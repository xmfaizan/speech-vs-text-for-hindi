{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8784850,
          "sourceType": "datasetVersion",
          "datasetId": 5281104
        }
      ],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'gggsdsd:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5281104%2F8784850%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240721%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240721T105604Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D52539993b40a1de6a1e368eab14a519839916c5037d687147e5575fcffba9a3f0347c14d8906b58f0726a1ffb1d496af73326ab0a8c69fb6d9314a5df2afec8a377150a2ef30aeca2d24261c4eb2d431b633eb8f96c3510896b8ca9136009c01afd1f4e42c832d81fa2eb6cf212e9abcc2edef5b6cd8dfc32f1b63754b4c4c61a00ddde68857fa037916453374c94057c30f048e89a8157b883e36e115f00ccdf351d44b23f682858103f33a79671b4af72c952cb3cf5d2a3d6b9d27a93d57ddc5f9c78b489ebbf831c62d5bd684a1eff1230f21dddd8d97f0d7a88aca657e3eb3a06f4c170bb3357c11e2a7f8b7696f3fdd3dfa0dbde57a17af4328157fd447'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "5f8bbjwc70OT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:41.783429Z",
          "iopub.execute_input": "2024-07-21T07:11:41.784068Z",
          "iopub.status.idle": "2024-07-21T07:11:42.266851Z",
          "shell.execute_reply.started": "2024-07-21T07:11:41.784035Z",
          "shell.execute_reply": "2024-07-21T07:11:42.265923Z"
        },
        "trusted": true,
        "id": "9ELyJCEa70OV",
        "outputId": "c978ce85-97d9-4b98-95c9-ae59ef8ef0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/gggsdsd/balanced.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:44.738535Z",
          "iopub.execute_input": "2024-07-21T07:11:44.738999Z",
          "iopub.status.idle": "2024-07-21T07:11:50.072497Z",
          "shell.execute_reply.started": "2024-07-21T07:11:44.738972Z",
          "shell.execute_reply": "2024-07-21T07:11:50.071685Z"
        },
        "trusted": true,
        "id": "jDTZIBkL70OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hindi_data(data_file):\n",
        "    df = pd.read_csv(data_file,encoding='utf-8')\n",
        "    texts = df['texts'].tolist()\n",
        "    labels = df['label'].tolist()\n",
        "    return texts, labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:51.319165Z",
          "iopub.execute_input": "2024-07-21T07:11:51.320227Z",
          "iopub.status.idle": "2024-07-21T07:11:51.327981Z",
          "shell.execute_reply.started": "2024-07-21T07:11:51.320181Z",
          "shell.execute_reply": "2024-07-21T07:11:51.327111Z"
        },
        "trusted": true,
        "id": "KzRsCwNd70OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = '/kaggle/input/gggsdsd/balanced.csv'\n",
        "texts, labels = hindi_data(data_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:51.734544Z",
          "iopub.execute_input": "2024-07-21T07:11:51.734859Z",
          "iopub.status.idle": "2024-07-21T07:11:52.012697Z",
          "shell.execute_reply.started": "2024-07-21T07:11:51.734834Z",
          "shell.execute_reply": "2024-07-21T07:11:52.011851Z"
        },
        "trusted": true,
        "id": "7tIjdoK270OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total texts: {len(texts)}, Total labels: {len(labels)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:52.01403Z",
          "iopub.execute_input": "2024-07-21T07:11:52.014316Z",
          "iopub.status.idle": "2024-07-21T07:11:52.019035Z",
          "shell.execute_reply.started": "2024-07-21T07:11:52.014292Z",
          "shell.execute_reply": "2024-07-21T07:11:52.018162Z"
        },
        "trusted": true,
        "id": "TZDclfrZ70OY",
        "outputId": "10129e71-65da-41b6-ff0d-842c17504772"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total texts: 38688, Total labels: 38688\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing, handling the seq_length, and providing with input IDs, attention masks, and labels\n",
        "class TextClassificationDataset(Dataset):\n",
        "  def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        except ValueError as e:\n",
        "            print(f\"Skipping example at index {idx}: {e}\")\n",
        "            return None\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:52.22398Z",
          "iopub.execute_input": "2024-07-21T07:11:52.224255Z",
          "iopub.status.idle": "2024-07-21T07:11:52.232829Z",
          "shell.execute_reply.started": "2024-07-21T07:11:52.224231Z",
          "shell.execute_reply": "2024-07-21T07:11:52.232072Z"
        },
        "trusted": true,
        "id": "1uFc0Zgu70OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_classes):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.fc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:52.403052Z",
          "iopub.execute_input": "2024-07-21T07:11:52.403301Z",
          "iopub.status.idle": "2024-07-21T07:11:52.40961Z",
          "shell.execute_reply.started": "2024-07-21T07:11:52.403278Z",
          "shell.execute_reply": "2024-07-21T07:11:52.408657Z"
        },
        "trusted": true,
        "id": "p2raWK2v70OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)  # Correct key is 'labels'\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:52.599289Z",
          "iopub.execute_input": "2024-07-21T07:11:52.599631Z",
          "iopub.status.idle": "2024-07-21T07:11:52.60572Z",
          "shell.execute_reply.started": "2024-07-21T07:11:52.599604Z",
          "shell.execute_reply": "2024-07-21T07:11:52.604825Z"
        },
        "trusted": true,
        "id": "ex9a0v6w70Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)  # Correct key is 'labels'\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:52.810221Z",
          "iopub.execute_input": "2024-07-21T07:11:52.811273Z",
          "iopub.status.idle": "2024-07-21T07:11:52.817836Z",
          "shell.execute_reply.started": "2024-07-21T07:11:52.811237Z",
          "shell.execute_reply": "2024-07-21T07:11:52.816879Z"
        },
        "trusted": true,
        "id": "am-JmNFA70Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function to handle the batching of data.\n",
        "    \"\"\"\n",
        "    # Filter out None items\n",
        "    batch = [item for item in batch if item is not None]\n",
        "\n",
        "    if not batch:  # Handle the case where all items in the batch are None\n",
        "        return None\n",
        "\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_mask = [item['attention_mask'] for item in batch]\n",
        "    labels = [item['labels'] for item in batch]\n",
        "\n",
        "    # Pad sequences to the same length\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Convert labels to a tensor\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'labels': labels\n",
        "    }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:53.023801Z",
          "iopub.execute_input": "2024-07-21T07:11:53.024151Z",
          "iopub.status.idle": "2024-07-21T07:11:53.031964Z",
          "shell.execute_reply.started": "2024-07-21T07:11:53.024123Z",
          "shell.execute_reply": "2024-07-21T07:11:53.030931Z"
        },
        "trusted": true,
        "id": "J1B-T09i70Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    return \"spoken\" if preds.item() == 1 else \"written\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:53.18406Z",
          "iopub.execute_input": "2024-07-21T07:11:53.184326Z",
          "iopub.status.idle": "2024-07-21T07:11:53.190639Z",
          "shell.execute_reply.started": "2024-07-21T07:11:53.184302Z",
          "shell.execute_reply": "2024-07-21T07:11:53.189774Z"
        },
        "trusted": true,
        "id": "Jw2zqaYn70Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up parameters\n",
        "bert_model_name = 'bert-base-uncased'\n",
        "num_classes = 2\n",
        "max_length = 128\n",
        "batch_size = 16\n",
        "num_epochs = 4\n",
        "learning_rate = 1e-5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:53.443476Z",
          "iopub.execute_input": "2024-07-21T07:11:53.443763Z",
          "iopub.status.idle": "2024-07-21T07:11:53.447778Z",
          "shell.execute_reply.started": "2024-07-21T07:11:53.443739Z",
          "shell.execute_reply": "2024-07-21T07:11:53.446915Z"
        },
        "trusted": true,
        "id": "g_W90JWJ70Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, rem_texts, train_labels, rem_labels = train_test_split(texts, labels, train_size=0.7, random_state=42)\n",
        "\n",
        "# Then split the remaining data into 67% validation and 33% test (which is 20% and 10% of total each)\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(rem_texts, rem_labels, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:53.69875Z",
          "iopub.execute_input": "2024-07-21T07:11:53.699048Z",
          "iopub.status.idle": "2024-07-21T07:11:53.731469Z",
          "shell.execute_reply.started": "2024-07-21T07:11:53.699023Z",
          "shell.execute_reply": "2024-07-21T07:11:53.730801Z"
        },
        "trusted": true,
        "id": "Yahg5jBd70Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_texts))\n",
        "print(len(train_labels))\n",
        "print(len(val_texts))\n",
        "print(len(val_labels))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:53.91924Z",
          "iopub.execute_input": "2024-07-21T07:11:53.920025Z",
          "iopub.status.idle": "2024-07-21T07:11:53.925428Z",
          "shell.execute_reply.started": "2024-07-21T07:11:53.919988Z",
          "shell.execute_reply": "2024-07-21T07:11:53.924585Z"
        },
        "trusted": true,
        "id": "yS8vtUR870Oe",
        "outputId": "83cb601a-d5c2-43a3-c6ca-c05db593aea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "27081\n27081\n7776\n7776\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:54.203237Z",
          "iopub.execute_input": "2024-07-21T07:11:54.203545Z",
          "iopub.status.idle": "2024-07-21T07:11:55.169366Z",
          "shell.execute_reply.started": "2024-07-21T07:11:54.203519Z",
          "shell.execute_reply": "2024-07-21T07:11:55.168618Z"
        },
        "trusted": true,
        "id": "l1NL5UQr70Oe",
        "outputId": "90d369bd-818e-4bcf-dc85-68304703542c",
        "colab": {
          "referenced_widgets": [
            "78427705e17f42f4ae693a966e70eeb1",
            "50e099f2f06741528f337d2eaace4567",
            "ad5e03b8b154487ab7097d18227eaacd",
            "52053b5f32474df1a737343bb7473ad5"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78427705e17f42f4ae693a966e70eeb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50e099f2f06741528f337d2eaace4567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5e03b8b154487ab7097d18227eaacd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52053b5f32474df1a737343bb7473ad5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:55.170795Z",
          "iopub.execute_input": "2024-07-21T07:11:55.171072Z",
          "iopub.status.idle": "2024-07-21T07:11:59.061973Z",
          "shell.execute_reply.started": "2024-07-21T07:11:55.171048Z",
          "shell.execute_reply": "2024-07-21T07:11:59.061011Z"
        },
        "trusted": true,
        "id": "asZAFOaW70Oe",
        "outputId": "e2521c8d-e992-4327-d040-17ac973b64e6",
        "colab": {
          "referenced_widgets": [
            "945f1d0b7bf44a1097ddb3076eb7f4df"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "945f1d0b7bf44a1097ddb3076eb7f4df"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    train(model, train_dataloader, optimizer, scheduler, device)\n",
        "    accuracy, report = evaluate(model, val_dataloader, device)\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:11:59.063182Z",
          "iopub.execute_input": "2024-07-21T07:11:59.063731Z",
          "iopub.status.idle": "2024-07-21T07:37:20.273094Z",
          "shell.execute_reply.started": "2024-07-21T07:11:59.063696Z",
          "shell.execute_reply": "2024-07-21T07:37:20.271989Z"
        },
        "trusted": true,
        "id": "y0o8OITK70Of",
        "outputId": "8a334251-b975-43cd-ffe5-75c666f2ca72"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/4\nValidation Accuracy: 0.9471\n              precision    recall  f1-score   support\n\n           0       0.94      0.95      0.95      3860\n           1       0.95      0.95      0.95      3916\n\n    accuracy                           0.95      7776\n   macro avg       0.95      0.95      0.95      7776\nweighted avg       0.95      0.95      0.95      7776\n\nEpoch 2/4\nValidation Accuracy: 0.9592\n              precision    recall  f1-score   support\n\n           0       0.97      0.95      0.96      3860\n           1       0.95      0.97      0.96      3916\n\n    accuracy                           0.96      7776\n   macro avg       0.96      0.96      0.96      7776\nweighted avg       0.96      0.96      0.96      7776\n\nEpoch 3/4\nValidation Accuracy: 0.9609\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96      3860\n           1       0.96      0.96      0.96      3916\n\n    accuracy                           0.96      7776\n   macro avg       0.96      0.96      0.96      7776\nweighted avg       0.96      0.96      0.96      7776\n\nEpoch 4/4\nValidation Accuracy: 0.9639\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96      3860\n           1       0.97      0.96      0.96      3916\n\n    accuracy                           0.96      7776\n   macro avg       0.96      0.96      0.96      7776\nweighted avg       0.96      0.96      0.96      7776\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "test_accuracy, test_report = evaluate(model, test_dataloader, device)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(test_report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T07:37:20.27533Z",
          "iopub.execute_input": "2024-07-21T07:37:20.27596Z",
          "iopub.status.idle": "2024-07-21T07:37:38.47976Z",
          "shell.execute_reply.started": "2024-07-21T07:37:20.275924Z",
          "shell.execute_reply": "2024-07-21T07:37:38.478659Z"
        },
        "trusted": true,
        "id": "BhzdRCWR70Of",
        "outputId": "84b7362b-a85b-486f-8a31-95cced3508d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test Accuracy: 0.9650\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.97      1922\n           1       0.97      0.96      0.96      1909\n\n    accuracy                           0.97      3831\n   macro avg       0.97      0.97      0.97      3831\nweighted avg       0.97      0.97      0.97      3831\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tpLmaPKM70Of"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}