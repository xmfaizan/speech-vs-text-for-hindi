{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8784850,"sourceType":"datasetVersion","datasetId":5281104}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def hindi_data(data_file):\n    df = pd.read_csv(data_file,encoding='utf-8')\n    texts = df['texts'].tolist()\n    labels = df['label'].tolist()\n    return texts, labels# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T06:52:20.993344Z","iopub.execute_input":"2024-06-26T06:52:20.994108Z","iopub.status.idle":"2024-06-26T06:52:21.002033Z","shell.execute_reply.started":"2024-06-26T06:52:20.994077Z","shell.execute_reply":"2024-06-26T06:52:21.001173Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/gggsdsd/balanced.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Using the balanced dataset (equal number of written and spoken texts)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:52:21.931826Z","iopub.execute_input":"2024-06-26T06:52:21.932183Z","iopub.status.idle":"2024-06-26T06:52:26.415582Z","shell.execute_reply.started":"2024-06-26T06:52:21.932154Z","shell.execute_reply":"2024-06-26T06:52:26.414603Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def hindi_data(data_file):\n    df = pd.read_csv(data_file,encoding='utf-8')\n    texts = df['texts'].tolist()\n    labels = df['label'].tolist()\n    return texts, labels","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:10.145526Z","iopub.execute_input":"2024-06-26T06:53:10.145879Z","iopub.status.idle":"2024-06-26T06:53:10.150934Z","shell.execute_reply.started":"2024-06-26T06:53:10.145851Z","shell.execute_reply":"2024-06-26T06:53:10.149911Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_file = '/kaggle/input/gggsdsd/balanced.csv'\ntexts, labels = hindi_data(data_file)\ntexts, labels = hindi_data(data_file)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:10.402255Z","iopub.execute_input":"2024-06-26T06:53:10.402927Z","iopub.status.idle":"2024-06-26T06:53:10.877274Z","shell.execute_reply.started":"2024-06-26T06:53:10.402894Z","shell.execute_reply":"2024-06-26T06:53:10.876313Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(f\"Total texts: {len(texts)}, Total labels: {len(labels)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:10.878863Z","iopub.execute_input":"2024-06-26T06:53:10.879134Z","iopub.status.idle":"2024-06-26T06:53:10.884040Z","shell.execute_reply.started":"2024-06-26T06:53:10.879110Z","shell.execute_reply":"2024-06-26T06:53:10.883177Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Total texts: 38688, Total labels: 38688\n","output_type":"stream"}]},{"cell_type":"code","source":"#tokenizing, handling the seq_length, and providing with input IDs, attention masks, and labels\nclass TextClassificationDataset(Dataset):\n  def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n  def __len__(self):\n        return len(self.texts)\n\n  def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        try:\n            encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        except ValueError as e:\n            print(f\"Skipping example at index {idx}: {e}\")\n            return None\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:11.001529Z","iopub.execute_input":"2024-06-26T06:53:11.001865Z","iopub.status.idle":"2024-06-26T06:53:11.009798Z","shell.execute_reply.started":"2024-06-26T06:53:11.001840Z","shell.execute_reply":"2024-06-26T06:53:11.008854Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.fc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:11.256757Z","iopub.execute_input":"2024-06-26T06:53:11.257102Z","iopub.status.idle":"2024-06-26T06:53:11.263714Z","shell.execute_reply.started":"2024-06-26T06:53:11.257073Z","shell.execute_reply":"2024-06-26T06:53:11.262828Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)  # Correct key is 'labels'\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:11.513495Z","iopub.execute_input":"2024-06-26T06:53:11.514294Z","iopub.status.idle":"2024-06-26T06:53:11.520064Z","shell.execute_reply.started":"2024-06-26T06:53:11.514263Z","shell.execute_reply":"2024-06-26T06:53:11.519183Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)  # Correct key is 'labels'\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:11.758323Z","iopub.execute_input":"2024-06-26T06:53:11.759115Z","iopub.status.idle":"2024-06-26T06:53:11.765542Z","shell.execute_reply.started":"2024-06-26T06:53:11.759083Z","shell.execute_reply":"2024-06-26T06:53:11.764673Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n\ndef collate_fn(batch):\n    \"\"\"\n    Custom collate function to handle the batching of data.\n    \"\"\"\n    # Filter out None items\n    batch = [item for item in batch if item is not None]\n\n    if not batch:  # Handle the case where all items in the batch are None\n        return None\n\n    input_ids = [item['input_ids'] for item in batch]\n    attention_mask = [item['attention_mask'] for item in batch]\n    labels = [item['labels'] for item in batch]\n\n    # Pad sequences to the same length\n    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n\n    # Convert labels to a tensor\n    labels = torch.tensor(labels)\n\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'labels': labels\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:12.016201Z","iopub.execute_input":"2024-06-26T06:53:12.016612Z","iopub.status.idle":"2024-06-26T06:53:12.023647Z","shell.execute_reply.started":"2024-06-26T06:53:12.016582Z","shell.execute_reply":"2024-06-26T06:53:12.022718Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def prediction(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n\n    return \"spoken\" if preds.item() == 1 else \"written\"","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:53:12.288607Z","iopub.execute_input":"2024-06-26T06:53:12.289369Z","iopub.status.idle":"2024-06-26T06:53:12.295625Z","shell.execute_reply.started":"2024-06-26T06:53:12.289334Z","shell.execute_reply":"2024-06-26T06:53:12.294698Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Set up parameters\nbert_model_name = 'bert-base-uncased'\nnum_classes = 2\nmax_length = 128\nbatch_size = 16\nnum_epochs = 4\nlearning_rate = 1e-5","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:59:41.154071Z","iopub.execute_input":"2024-06-26T06:59:41.154523Z","iopub.status.idle":"2024-06-26T06:59:41.159251Z","shell.execute_reply.started":"2024-06-26T06:59:41.154493Z","shell.execute_reply":"2024-06-26T06:59:41.158269Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_texts, rem_texts, train_labels, rem_labels = train_test_split(texts, labels, train_size=0.6, random_state=42)\n\n# Then split the remaining data into 50% validation and 50% test (which is 20% of total each)\nval_texts, test_texts, val_labels, test_labels = train_test_split(rem_texts, rem_labels, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:59:57.702372Z","iopub.execute_input":"2024-06-26T06:59:57.702743Z","iopub.status.idle":"2024-06-26T06:59:57.736964Z","shell.execute_reply.started":"2024-06-26T06:59:57.702714Z","shell.execute_reply":"2024-06-26T06:59:57.735830Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(len(train_texts))\nprint(len(train_labels))\nprint(len(val_texts))\nprint(len(val_labels))","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:59:58.094775Z","iopub.execute_input":"2024-06-26T06:59:58.095600Z","iopub.status.idle":"2024-06-26T06:59:58.100540Z","shell.execute_reply.started":"2024-06-26T06:59:58.095567Z","shell.execute_reply":"2024-06-26T06:59:58.099475Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"23212\n23212\n7738\n7738\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = BertTokenizer.from_pretrained(bert_model_name)\n\n# Create datasets\ntrain_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\nval_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n\n# Create dataloaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T06:59:58.681124Z","iopub.execute_input":"2024-06-26T06:59:58.681989Z","iopub.status.idle":"2024-06-26T06:59:58.864731Z","shell.execute_reply.started":"2024-06-26T06:59:58.681954Z","shell.execute_reply":"2024-06-26T06:59:58.863873Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BERTClassifier(bert_model_name, num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:00:03.429839Z","iopub.execute_input":"2024-06-26T07:00:03.430203Z","iopub.status.idle":"2024-06-26T07:00:04.004977Z","shell.execute_reply.started":"2024-06-26T07:00:03.430172Z","shell.execute_reply":"2024-06-26T07:00:04.003997Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:00:04.006475Z","iopub.execute_input":"2024-06-26T07:00:04.006765Z","iopub.status.idle":"2024-06-26T07:00:04.016529Z","shell.execute_reply.started":"2024-06-26T07:00:04.006741Z","shell.execute_reply":"2024-06-26T07:00:04.015344Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train(model, train_dataloader, optimizer, scheduler, device)\n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:00:05.085695Z","iopub.execute_input":"2024-06-26T07:00:05.086277Z","iopub.status.idle":"2024-06-26T07:22:07.294546Z","shell.execute_reply.started":"2024-06-26T07:00:05.086249Z","shell.execute_reply":"2024-06-26T07:22:07.293583Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1/4\nValidation Accuracy: 0.9429\n              precision    recall  f1-score   support\n\n           0       0.95      0.93      0.94      3869\n           1       0.93      0.95      0.94      3869\n\n    accuracy                           0.94      7738\n   macro avg       0.94      0.94      0.94      7738\nweighted avg       0.94      0.94      0.94      7738\n\nEpoch 2/4\nValidation Accuracy: 0.9510\n              precision    recall  f1-score   support\n\n           0       0.97      0.93      0.95      3869\n           1       0.93      0.97      0.95      3869\n\n    accuracy                           0.95      7738\n   macro avg       0.95      0.95      0.95      7738\nweighted avg       0.95      0.95      0.95      7738\n\nEpoch 3/4\nValidation Accuracy: 0.9607\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96      3869\n           1       0.96      0.96      0.96      3869\n\n    accuracy                           0.96      7738\n   macro avg       0.96      0.96      0.96      7738\nweighted avg       0.96      0.96      0.96      7738\n\nEpoch 4/4\nValidation Accuracy: 0.9608\n              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96      3869\n           1       0.97      0.96      0.96      3869\n\n    accuracy                           0.96      7738\n   macro avg       0.96      0.96      0.96      7738\nweighted avg       0.96      0.96      0.96      7738\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\ntest_accuracy, test_report = evaluate(model, test_dataloader, device)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(test_report)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:31:54.166996Z","iopub.execute_input":"2024-06-26T07:31:54.167408Z","iopub.status.idle":"2024-06-26T07:32:30.497048Z","shell.execute_reply.started":"2024-06-26T07:31:54.167355Z","shell.execute_reply":"2024-06-26T07:32:30.496120Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9620\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96      3847\n           1       0.96      0.96      0.96      3891\n\n    accuracy                           0.96      7738\n   macro avg       0.96      0.96      0.96      7738\nweighted avg       0.96      0.96      0.96      7738\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_text = \"सविनय निवेदन है कि मैं निवासी, इस पत्र के माध्यम से आपका ध्यान [विषय/मुद्दा] की ओर आकर्षित करना चाहता/चाहती हूँ।\"\npredict = prediction(test_text, model, tokenizer, device)\nprint(test_text)\nprint(f\"Predicted sentiment: {predict}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-26T07:52:18.871136Z","iopub.execute_input":"2024-06-26T07:52:18.871835Z","iopub.status.idle":"2024-06-26T07:52:18.920036Z","shell.execute_reply.started":"2024-06-26T07:52:18.871801Z","shell.execute_reply":"2024-06-26T07:52:18.919135Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"सविनय निवेदन है कि मैं निवासी, इस पत्र के माध्यम से आपका ध्यान [विषय/मुद्दा] की ओर आकर्षित करना चाहता/चाहती हूँ।\nPredicted sentiment: written\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}