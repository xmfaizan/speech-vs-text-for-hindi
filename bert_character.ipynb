{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8784850,
          "sourceType": "datasetVersion",
          "datasetId": 5281104
        }
      ],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'gggsdsd:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5281104%2F8784850%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240721%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240721T105556Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D56425025cd3caf943a92aa8ac693d66d4c6df8e2a4461deb409d3bc320e93698217001bdaa3a78c681d84e89b378fab04257ccbaef6e8339d9a94c5e66cc32a99e08aecc6ed4bb82ee7603022ce670920b665809cc2712d4ef98513ed878d176747f3d80c40402ddb8d00f4d6c129dae513923d695411a3180443d6b2030e0843f8b029229381c731dfea74c837e2d091d29e4ec92ac57bde6e5e6d5b54e14325ca79616315d94e9938e87e071ca5340ee2fd6f847c4d2701ff7552416fa52f5ae3ccb0521b2148ef7950558fbf706b735df46cf0ec4de9c369c7448f98b2cd16bead18a95025b88dbe3c9b6ea8f14542094257955291ca2601d48d1e0055f6d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "UJqjzr7g7yHJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:04.935519Z",
          "iopub.execute_input": "2024-07-21T10:34:04.9358Z",
          "iopub.status.idle": "2024-07-21T10:34:05.889023Z",
          "shell.execute_reply.started": "2024-07-21T10:34:04.935774Z",
          "shell.execute_reply": "2024-07-21T10:34:05.887937Z"
        },
        "trusted": true,
        "id": "lIFSzDv67yHN",
        "outputId": "a6011ef1-d775-4b44-b0e8-2a2cdac9b567"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/gggsdsd/balanced.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:24.171149Z",
          "iopub.execute_input": "2024-07-21T10:34:24.171908Z",
          "iopub.status.idle": "2024-07-21T10:34:29.250518Z",
          "shell.execute_reply.started": "2024-07-21T10:34:24.171877Z",
          "shell.execute_reply": "2024-07-21T10:34:29.249555Z"
        },
        "trusted": true,
        "id": "-nml4tqw7yHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hindi_data(data_file):\n",
        "    df = pd.read_csv(data_file, encoding='utf-8')\n",
        "    texts = df['texts'].tolist()\n",
        "    labels = df['label'].tolist()\n",
        "    return texts, labels\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.252105Z",
          "iopub.execute_input": "2024-07-21T10:34:29.252552Z",
          "iopub.status.idle": "2024-07-21T10:34:29.257529Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.252525Z",
          "shell.execute_reply": "2024-07-21T10:34:29.256428Z"
        },
        "trusted": true,
        "id": "g3Q9MzCx7yHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = '/kaggle/input/gggsdsd/balanced.csv'\n",
        "texts, labels = hindi_data(data_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.258466Z",
          "iopub.execute_input": "2024-07-21T10:34:29.258728Z",
          "iopub.status.idle": "2024-07-21T10:34:29.547118Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.258706Z",
          "shell.execute_reply": "2024-07-21T10:34:29.546254Z"
        },
        "trusted": true,
        "id": "TV2Cd8HE7yHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total texts: {len(texts)}, Total labels: {len(labels)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.549786Z",
          "iopub.execute_input": "2024-07-21T10:34:29.550215Z",
          "iopub.status.idle": "2024-07-21T10:34:29.554992Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.550183Z",
          "shell.execute_reply": "2024-07-21T10:34:29.554078Z"
        },
        "trusted": true,
        "id": "SX-zMryj7yHR",
        "outputId": "9204c660-93be-448c-fa1b-352a97e8bd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total texts: 38688, Total labels: 38688\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharacterTokenizer:\n",
        "    def __init__(self, texts):\n",
        "        self.char_to_ix = {char: i+1 for i, char in enumerate(sorted(set(''.join(texts))))}\n",
        "        self.char_to_ix['<PAD>'] = 0\n",
        "        self.ix_to_char = {i: char for char, i in self.char_to_ix.items()}\n",
        "\n",
        "    def __call__(self, text, max_length=128, padding='max_length', truncation=True):\n",
        "        char_ids = [self.char_to_ix.get(char, 0) for char in text[:max_length]]\n",
        "        if padding == 'max_length':\n",
        "            char_ids = char_ids + [0] * (max_length - len(char_ids))\n",
        "        attention_mask = [1] * len(char_ids)\n",
        "        return {\n",
        "            'input_ids': torch.tensor([char_ids]),\n",
        "            'attention_mask': torch.tensor([attention_mask])\n",
        "        }\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return len(self.char_to_ix)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.555997Z",
          "iopub.execute_input": "2024-07-21T10:34:29.556314Z",
          "iopub.status.idle": "2024-07-21T10:34:29.566816Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.556282Z",
          "shell.execute_reply": "2024-07-21T10:34:29.565871Z"
        },
        "trusted": true,
        "id": "re94_agn7yHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_classes):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.bert.embeddings.word_embeddings = self.embedding\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.dropout(pooled_output)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.567767Z",
          "iopub.execute_input": "2024-07-21T10:34:29.567993Z",
          "iopub.status.idle": "2024-07-21T10:34:29.579833Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.567973Z",
          "shell.execute_reply": "2024-07-21T10:34:29.578973Z"
        },
        "trusted": true,
        "id": "kL6PjiQK7yHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.580849Z",
          "iopub.execute_input": "2024-07-21T10:34:29.581121Z",
          "iopub.status.idle": "2024-07-21T10:34:29.59254Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.581086Z",
          "shell.execute_reply": "2024-07-21T10:34:29.591724Z"
        },
        "trusted": true,
        "id": "_r04P4ju7yHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.593596Z",
          "iopub.execute_input": "2024-07-21T10:34:29.594346Z",
          "iopub.status.idle": "2024-07-21T10:34:29.60225Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.594308Z",
          "shell.execute_reply": "2024-07-21T10:34:29.601412Z"
        },
        "trusted": true,
        "id": "xEsHsVfM7yHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(text, model, tokenizer, device, max_length=128):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "    return \"spoken\" if preds.item() == 1 else \"written\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.603197Z",
          "iopub.execute_input": "2024-07-21T10:34:29.603477Z",
          "iopub.status.idle": "2024-07-21T10:34:29.615075Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.603455Z",
          "shell.execute_reply": "2024-07-21T10:34:29.614259Z"
        },
        "trusted": true,
        "id": "uaSt_NJs7yHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up parameters\n",
        "num_classes = 2\n",
        "max_length = 128\n",
        "batch_size = 16\n",
        "num_epochs = 4\n",
        "learning_rate = 1e-5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.618466Z",
          "iopub.execute_input": "2024-07-21T10:34:29.618727Z",
          "iopub.status.idle": "2024-07-21T10:34:29.624346Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.618705Z",
          "shell.execute_reply": "2024-07-21T10:34:29.623537Z"
        },
        "trusted": true,
        "id": "HTtEjdK17yHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_texts, rem_texts, train_labels, rem_labels = train_test_split(texts, labels, train_size=0.6, random_state=42)\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(rem_texts, rem_labels, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.625279Z",
          "iopub.execute_input": "2024-07-21T10:34:29.625528Z",
          "iopub.status.idle": "2024-07-21T10:34:29.658909Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.625506Z",
          "shell.execute_reply": "2024-07-21T10:34:29.658247Z"
        },
        "trusted": true,
        "id": "lOOdhTOx7yHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create character-level tokenizer\n",
        "tokenizer = CharacterTokenizer(texts)\n",
        "vocab_size = tokenizer.get_vocab_size()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.659874Z",
          "iopub.execute_input": "2024-07-21T10:34:29.660138Z",
          "iopub.status.idle": "2024-07-21T10:34:29.915397Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.660116Z",
          "shell.execute_reply": "2024-07-21T10:34:29.91444Z"
        },
        "trusted": true,
        "id": "VkXIWPRq7yHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
        "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
        "test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.916559Z",
          "iopub.execute_input": "2024-07-21T10:34:29.916834Z",
          "iopub.status.idle": "2024-07-21T10:34:29.925248Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.916811Z",
          "shell.execute_reply": "2024-07-21T10:34:29.924495Z"
        },
        "trusted": true,
        "id": "PV9_UBiV7yHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.926193Z",
          "iopub.execute_input": "2024-07-21T10:34:29.926499Z",
          "iopub.status.idle": "2024-07-21T10:34:29.934476Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.926457Z",
          "shell.execute_reply": "2024-07-21T10:34:29.933527Z"
        },
        "trusted": true,
        "id": "4B67ilSF7yHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BERTClassifier(vocab_size, 768, num_classes).to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:29.935448Z",
          "iopub.execute_input": "2024-07-21T10:34:29.935754Z",
          "iopub.status.idle": "2024-07-21T10:34:42.645777Z",
          "shell.execute_reply.started": "2024-07-21T10:34:29.93573Z",
          "shell.execute_reply": "2024-07-21T10:34:42.644953Z"
        },
        "trusted": true,
        "id": "cIzVy4n07yHX",
        "outputId": "d221b079-72c0-4149-c529-6aa3766e0537",
        "colab": {
          "referenced_widgets": [
            "70584232aa394a9bac5b810e5073b9a9",
            "6d0441854fa442a5aa1ce848d5374a61"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70584232aa394a9bac5b810e5073b9a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d0441854fa442a5aa1ce848d5374a61"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:42.646877Z",
          "iopub.execute_input": "2024-07-21T10:34:42.647153Z",
          "iopub.status.idle": "2024-07-21T10:34:43.221507Z",
          "shell.execute_reply.started": "2024-07-21T10:34:42.647129Z",
          "shell.execute_reply": "2024-07-21T10:34:43.220625Z"
        },
        "trusted": true,
        "id": "EPWfe4Q97yHY",
        "outputId": "4334d404-83e4-4cae-81c6-f8fcdc3d37c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    train(model, train_dataloader, optimizer, scheduler, device)\n",
        "    accuracy, report = evaluate(model, val_dataloader, device)\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:34:43.222592Z",
          "iopub.execute_input": "2024-07-21T10:34:43.223018Z",
          "iopub.status.idle": "2024-07-21T10:54:17.39036Z",
          "shell.execute_reply.started": "2024-07-21T10:34:43.222991Z",
          "shell.execute_reply": "2024-07-21T10:54:17.389246Z"
        },
        "trusted": true,
        "id": "HN6CB-oJ7yHY",
        "outputId": "0ab62d44-3966-401c-8873-e441614652bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/4\nValidation Accuracy: 0.9203\n              precision    recall  f1-score   support\n\n           0       0.93      0.91      0.92      3869\n           1       0.91      0.93      0.92      3869\n\n    accuracy                           0.92      7738\n   macro avg       0.92      0.92      0.92      7738\nweighted avg       0.92      0.92      0.92      7738\n\nEpoch 2/4\nValidation Accuracy: 0.9227\n              precision    recall  f1-score   support\n\n           0       0.94      0.90      0.92      3869\n           1       0.90      0.95      0.92      3869\n\n    accuracy                           0.92      7738\n   macro avg       0.92      0.92      0.92      7738\nweighted avg       0.92      0.92      0.92      7738\n\nEpoch 3/4\nValidation Accuracy: 0.9315\n              precision    recall  f1-score   support\n\n           0       0.91      0.95      0.93      3869\n           1       0.95      0.91      0.93      3869\n\n    accuracy                           0.93      7738\n   macro avg       0.93      0.93      0.93      7738\nweighted avg       0.93      0.93      0.93      7738\n\nEpoch 4/4\nValidation Accuracy: 0.9367\n              precision    recall  f1-score   support\n\n           0       0.94      0.93      0.94      3869\n           1       0.93      0.94      0.94      3869\n\n    accuracy                           0.94      7738\n   macro avg       0.94      0.94      0.94      7738\nweighted avg       0.94      0.94      0.94      7738\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy, test_report = evaluate(model, test_dataloader, device)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(test_report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-21T10:54:17.391368Z",
          "iopub.execute_input": "2024-07-21T10:54:17.39165Z",
          "iopub.status.idle": "2024-07-21T10:54:43.660842Z",
          "shell.execute_reply.started": "2024-07-21T10:54:17.391625Z",
          "shell.execute_reply": "2024-07-21T10:54:43.659887Z"
        },
        "trusted": true,
        "id": "QJCIWOJl7yHZ",
        "outputId": "8b301981-937c-464a-ab57-7d5e1524dfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test Accuracy: 0.9331\n              precision    recall  f1-score   support\n\n           0       0.94      0.93      0.93      3847\n           1       0.93      0.94      0.93      3891\n\n    accuracy                           0.93      7738\n   macro avg       0.93      0.93      0.93      7738\nweighted avg       0.93      0.93      0.93      7738\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0nsT1pte7yHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}